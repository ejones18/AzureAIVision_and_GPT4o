{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Use the Azure AI Language Service\n",
        "First make sure you have created an AML environment and jupyter kernel as in Notebook 1.\n",
        "\n",
        "Test that you have selected the correct code by running the cell below."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "print(emoji.emojize('Python is :thumbs_up:'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Python is üëç\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1726564614073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create Azure AI Language Resource \n",
        "- Rename credentials_template.env to credentials.env (if not already)\n",
        "- Fill in the endpoint and key in credentials.env \n",
        "[Detailed Instructions](https://learn.microsoft.com/en-us/azure/ai-services/language-service/language-detection/quickstart?tabs=windows&pivots=programming-language-python)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads in environement varaibles from credentials.env. \n",
        "# Note that if you change the contents of credentials.env you will need to restart your python kernel as well as rerun this cell.\n",
        "import os\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "endpoint = os.environ.get(\"AZURE_LANGUAGE_ENDPOINT\")\n",
        "api_key = os.environ.get(\"AZURE_LANGUAGE_KEY\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1726564616412
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Endpoint: \", endpoint)\n",
        "print(\"API Key: \", api_key)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint:  https://language-sa.cognitiveservices.azure.com/\nAPI Key:  be87a11bd52e4e97aa698f564026b2a4\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1726564618111
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create credentials and Language Client (note this was previously called text analytics)\n",
        "\n",
        "credential = AzureKeyCredential(api_key)\n",
        "client = TextAnalyticsClient(endpoint=endpoint, credential=credential)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1726564619921
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Language Detection\n",
        "\n",
        "Try replacing the text you give the detector to give different results."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "documents = [\"Ce document est r√©dig√© en Fran√ßais.\"]\n",
        "\n",
        "\n",
        "response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
        "print(\"Language: \", response.primary_language.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language:  French\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1726564621853
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentiment Analysis\n",
        "\n",
        "Try replacing the text you give the detector to give different results. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"The food and service were unacceptable. The concierge was nice, however.\",\n",
        "    \"It was a pretty place but evening was terrible, I got food poisoning and had to go to hospital\",\n",
        "    \"Lovely little place, would go again\"\n",
        "]\n",
        "\n",
        "result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
        "doc_result = [doc for doc in result if not doc.is_error]\n",
        "\n",
        "\n",
        "for document in doc_result:\n",
        "    print(\"Document Sentiment: {}\".format(document.sentiment))\n",
        "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
        "        document.confidence_scores.positive,\n",
        "        document.confidence_scores.neutral,\n",
        "        document.confidence_scores.negative,\n",
        "        ))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Document Sentiment: mixed\nOverall scores: positive=0.30; neutral=0.17; negative=0.52 \n\nDocument Sentiment: negative\nOverall scores: positive=0.00; neutral=0.00; negative=1.00 \n\nDocument Sentiment: positive\nOverall scores: positive=1.00; neutral=0.00; negative=0.00 \n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1726564624399
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Named Entity Extraction\n",
        "\n",
        "Try replacing the text you give the detector to give different results. \n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"\"\"The Admiralty's first Hydrographer was Alexander Dalrymple, appointed in 1795 on the order of King George III and the existing charts were brought together and catalogued. The first chart Dalrymple published as Hydrographer to the Admiralty (of Quiberon Bay in Brittany) did not appear until 1800. He also issued Sailing Directions and Notices to Mariners (NMs)\n",
        "\"\"\"]\n",
        "result = client.recognize_entities(documents = documents)[0]\n",
        "\n",
        "print(\"Named Entities:\\n\")\n",
        "for entity in result.entities:\n",
        "    print(\"Text: \\t\", entity.text, \"\\nCategory: \\t\", entity.category, \"\\nSubCategory: \\t\", entity.subcategory,\n",
        "            \"\\nConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\nLength: \\t\", entity.length, \"\\nOffset: \\t\", entity.offset, \"\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Named Entities:\n\nText: \t Admiralty \nCategory: \t Organization \nSubCategory: \t None \nConfidence Score: \t 0.58 \nLength: \t 9 \nOffset: \t 4 \n\nText: \t first \nCategory: \t Quantity \nSubCategory: \t Ordinal \nConfidence Score: \t 0.98 \nLength: \t 5 \nOffset: \t 16 \n\nText: \t Hydrographer \nCategory: \t PersonType \nSubCategory: \t None \nConfidence Score: \t 0.96 \nLength: \t 12 \nOffset: \t 22 \n\nText: \t Alexander Dalrymple \nCategory: \t Person \nSubCategory: \t None \nConfidence Score: \t 1.0 \nLength: \t 19 \nOffset: \t 39 \n\nText: \t 1795 \nCategory: \t DateTime \nSubCategory: \t DateRange \nConfidence Score: \t 1.0 \nLength: \t 4 \nOffset: \t 73 \n\nText: \t George III \nCategory: \t Person \nSubCategory: \t None \nConfidence Score: \t 0.92 \nLength: \t 10 \nOffset: \t 99 \n\nText: \t first \nCategory: \t Quantity \nSubCategory: \t Ordinal \nConfidence Score: \t 0.97 \nLength: \t 5 \nOffset: \t 176 \n\nText: \t Dalrymple \nCategory: \t Person \nSubCategory: \t None \nConfidence Score: \t 1.0 \nLength: \t 9 \nOffset: \t 188 \n\nText: \t Hydrographer \nCategory: \t PersonType \nSubCategory: \t None \nConfidence Score: \t 0.54 \nLength: \t 12 \nOffset: \t 211 \n\nText: \t Quiberon Bay \nCategory: \t Location \nSubCategory: \t None \nConfidence Score: \t 1.0 \nLength: \t 12 \nOffset: \t 245 \n\nText: \t Brittany \nCategory: \t Location \nSubCategory: \t GPE \nConfidence Score: \t 0.88 \nLength: \t 8 \nOffset: \t 261 \n\nText: \t until 1800 \nCategory: \t DateTime \nSubCategory: \t DateRange \nConfidence Score: \t 1.0 \nLength: \t 10 \nOffset: \t 286 \n\nText: \t Mariners \nCategory: \t PersonType \nSubCategory: \t None \nConfidence Score: \t 0.73 \nLength: \t 8 \nOffset: \t 347 \n\nText: \t NMs \nCategory: \t Location \nSubCategory: \t State \nConfidence Score: \t 0.99 \nLength: \t 3 \nOffset: \t 357 \n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1726564624541
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PII Detection\n",
        "Try replacing the text you give the detector to give different results. \n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "        \"The employee's SSN is 859-98-0987.\",\n",
        "        \"The employee's phone number is 555-555-5555.\",\n",
        "        \"The Admiralty's first Hydrographer was Alexander Dalrymple, appointed in 1795 on the order of King George III\"\n",
        "    ]\n",
        "response = client.recognize_pii_entities(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "for doc in result:\n",
        "    print(\"Redacted Text: {}\".format(doc.redacted_text))\n",
        "    for entity in doc.entities:\n",
        "        print(\"Entity: {}\".format(entity.text))\n",
        "        print(\"\\tCategory: {}\".format(entity.category))\n",
        "        print(\"\\tConfidence Score: {}\".format(entity.confidence_score))\n",
        "        print(\"\\tOffset: {}\".format(entity.offset))\n",
        "        print(\"\\tLength: {}\".format(entity.length))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Redacted Text: The ********'s SSN is ***********.\nEntity: employee\n\tCategory: PersonType\n\tConfidence Score: 0.99\n\tOffset: 4\n\tLength: 8\nEntity: 859-98-0987\n\tCategory: USSocialSecurityNumber\n\tConfidence Score: 0.85\n\tOffset: 22\n\tLength: 11\nRedacted Text: The ********'s phone number is ************.\nEntity: employee\n\tCategory: PersonType\n\tConfidence Score: 0.99\n\tOffset: 4\n\tLength: 8\nEntity: 555-555-5555\n\tCategory: PhoneNumber\n\tConfidence Score: 0.8\n\tOffset: 31\n\tLength: 12\nRedacted Text: The *********'s first ************ was *******************, appointed in 1795 on the order of King **********\nEntity: Admiralty\n\tCategory: Organization\n\tConfidence Score: 0.89\n\tOffset: 4\n\tLength: 9\nEntity: Hydrographer\n\tCategory: PersonType\n\tConfidence Score: 0.88\n\tOffset: 22\n\tLength: 12\nEntity: Alexander Dalrymple\n\tCategory: Person\n\tConfidence Score: 1.0\n\tOffset: 39\n\tLength: 19\nEntity: George III\n\tCategory: Person\n\tConfidence Score: 0.91\n\tOffset: 99\n\tLength: 10\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1726564624857
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "openai_env_upskilling"
    },
    "kernelspec": {
      "display_name": "Python openai_env_upskilling",
      "language": "python",
      "name": "openai_env_upskilling"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}